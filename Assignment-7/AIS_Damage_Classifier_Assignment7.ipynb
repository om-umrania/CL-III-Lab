{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cfa49ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# === Artificial Immune Pattern Recognition System for Structural Damage Classification ===\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Fulfilling Assignment 7 steps from Computer Lab III - Distributed Computing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# === Artificial Immune Pattern Recognition System for Structural Damage Classification ===\n",
    "# Fulfilling Assignment 7 steps from Computer Lab III - Distributed Computing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Simulate Structured Dataset (Replace this with real dataset for practical use)\n",
    "def generate_structural_data(samples=2000, features=8):\n",
    "    data = pd.DataFrame(np.random.rand(samples, features), columns=[f\"feature_{i+1}\" for i in range(features)])\n",
    "    data['district_id'] = np.random.choice(range(12, 37), samples)\n",
    "    data['damage_grade'] = np.random.choice(['Grade 1', 'Grade 2', 'Grade 3', 'Grade 4', 'Grade 5'], samples, p=[0.1, 0.15, 0.25, 0.25, 0.25])\n",
    "    data['land_surface_condition'] = np.random.choice(['Flat', 'Moderate slope', 'Steep slope'], samples, p=[0.82, 0.13, 0.05])\n",
    "    data['foundation_type'] = np.random.choice(['Mud mortar-Stone/Brick', 'Bamboo/Timber', 'Cement-Stone/Brick', 'RC', 'Other'], samples, p=[0.63, 0.1, 0.1, 0.1, 0.07])\n",
    "    data['roof_type'] = np.random.choice(['Bamboo/Timber-Light roof', 'Bamboo/Timber-Heavy roof', 'RCC/RB/RBC'], samples, p=[0.6, 0.25, 0.15])\n",
    "    data['ground_floor_type'] = np.random.choice(['Mud', 'RC', 'Brick/Stone', 'Timber', 'Other'], samples, p=[0.6, 0.12, 0.12, 0.1, 0.06])\n",
    "    data['other_floor_type'] = np.random.choice(['TImber/Bamboo-Mud', 'Timber-Planck', 'Not applicable', 'RCC/RB/RBC'], samples, p=[0.64, 0.16, 0.16, 0.04])\n",
    "    data['vdcmun_id'] = np.random.choice(range(1, 111), samples)\n",
    "    data['ward_id'] = np.random.choice(range(1, 946), samples)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "df_stru = generate_structural_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Exploration ===\n",
    "print(\"\\nInitial Glimpse of Dataset (df.head()):\")\n",
    "print(df_stru.head())\n",
    "\n",
    "print(\"\\nData Structure Overview (df.info()):\")\n",
    "df_stru.info()\n",
    "\n",
    "print(\"\\nStatistical Summary (df.describe()):\")\n",
    "print(df_stru.describe(include='all'))\n",
    "\n",
    "print(\"\\nColumn Data Types (df.dtypes):\")\n",
    "print(df_stru.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df_stru.select_dtypes(include=[np.number]).corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap of Numerical Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Value Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_stru.isnull(), cbar=False, cmap=\"viridis\")\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Introduce missing values\n",
    "df_stru.loc[np.random.choice(df_stru.index, 50), 'feature_2'] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Data\n",
    "df_temp = df_stru.isnull().sum().reset_index(name='count')\n",
    "print(df_temp[df_temp['count'] > 0])\n",
    "df_stru.dropna(inplace=True)\n",
    "\n",
    "# Display All Categorical Features\n",
    "print(\"\\nCategorical Feature Distributions:\")\n",
    "for col in ['land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', 'other_floor_type']:\n",
    "    print(f\"\\n{col} distribution:\")\n",
    "    print(df_stru[col].value_counts(normalize=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4432a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding of Categorical Features\n",
    "categorical_features = ['land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', 'other_floor_type']\n",
    "df_encoded = pd.get_dummies(df_stru[categorical_features], drop_first=True)\n",
    "\n",
    "# Combine with numerical features\n",
    "feature_cols = [col for col in df_stru.columns if col.startswith('feature_')]\n",
    "X_numeric = df_stru[feature_cols].reset_index(drop=True)\n",
    "X_combined = pd.concat([X_numeric, df_encoded.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X = X_combined.values\n",
    "y_map = {'Grade 1': 0, 'Grade 2': 1, 'Grade 3': 2, 'Grade 4': 3, 'Grade 5': 4}\n",
    "y = df_stru['damage_grade'].map(y_map).values\n",
    "\n",
    "# Normalize Features\n",
    "def encode_data(X):\n",
    "    return (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0) + 1e-6)\n",
    "X_encoded = encode_data(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced AIS Classifier with Mutation and Cloning\n",
    "class AISClassifier:\n",
    "    def __init__(self, num_detectors=10, mutation_rate=0.1, clone_rate=3, max_generations=10):\n",
    "        self.num_detectors = num_detectors\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.clone_rate = clone_rate\n",
    "        self.max_generations = max_generations\n",
    "        self.convergence_history = []\n",
    "\n",
    "    def _mutate(self, detector):\n",
    "        mutation_vector = np.random.normal(0, self.mutation_rate, size=detector.shape)\n",
    "        return np.clip(detector + mutation_vector, 0, 1)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.detectors = np.asarray(X_train[np.random.choice(len(X_train), self.num_detectors, replace=False)], dtype=np.float64)\n",
    "        self.labels = y_train[np.random.choice(len(y_train), self.num_detectors, replace=False)]\n",
    "\n",
    "        for gen in range(self.max_generations):\n",
    "            mutated_detectors = []\n",
    "            mutated_labels = []\n",
    "            distances = []\n",
    "\n",
    "            for i in range(len(self.detectors)):\n",
    "                for _ in range(self.clone_rate):\n",
    "                    clone = self.detectors[i].copy()\n",
    "                    mutated = self._mutate(clone)\n",
    "                    mutated_detectors.append(mutated)\n",
    "                    mutated_labels.append(self.labels[i])\n",
    "                    distance = np.linalg.norm(mutated - self.detectors[i])\n",
    "                    distances.append(distance)\n",
    "\n",
    "            avg_distance = np.mean(distances)\n",
    "            self.convergence_history.append(avg_distance)\n",
    "            self.detectors = np.array(mutated_detectors[:self.num_detectors])\n",
    "            self.labels = np.array(mutated_labels[:self.num_detectors])\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        self.detectors = np.asarray(self.detectors, dtype=np.float64)\n",
    "        for sample in X_test:\n",
    "            sample = np.asarray(sample, dtype=np.float64)\n",
    "            if sample.ndim > 1:\n",
    "                sample = sample.flatten()\n",
    "            distances = np.linalg.norm(self.detectors - sample, axis=1)\n",
    "            nearest = np.argmin(distances)\n",
    "            predictions.append(self.labels[nearest])\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def plot_convergence(self):\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(self.convergence_history, marker='o')\n",
    "        plt.title(\"Detector Convergence over Generations\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Average Mutation Distance\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e957c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split and Classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
    "model = AISClassifier(num_detectors=20, mutation_rate=0.05, clone_rate=4, max_generations=15)\n",
    "model.train(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, target_names=list(y_map.keys()))\n",
    "\n",
    "print(f\"\\nClassification Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report (Precision, Recall, F1-score):\")\n",
    "print(class_report)\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize Detector Convergence\n",
    "model.plot_convergence()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
